{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('C:/Users/2023/Downloads/dataset/cleaned_data_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SubmissionDate</th>\n",
       "      <th>starttime</th>\n",
       "      <th>endtime</th>\n",
       "      <th>deviceid</th>\n",
       "      <th>subscriberid</th>\n",
       "      <th>simid</th>\n",
       "      <th>devicephonenum</th>\n",
       "      <th>username</th>\n",
       "      <th>duration</th>\n",
       "      <th>interviewer_name</th>\n",
       "      <th>...</th>\n",
       "      <th>i_spend_entertainment</th>\n",
       "      <th>i_totalexp</th>\n",
       "      <th>i_expenditure</th>\n",
       "      <th>i_savings</th>\n",
       "      <th>i_loan</th>\n",
       "      <th>i_loan_amt</th>\n",
       "      <th>i_loan_rate</th>\n",
       "      <th>i_highest</th>\n",
       "      <th>i_lowest</th>\n",
       "      <th>formdef_version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-11-13 19:10:21</td>\n",
       "      <td>2021-11-13 13:12:59</td>\n",
       "      <td>2021-11-13 13:23:11</td>\n",
       "      <td>ef443f91bed409a9</td>\n",
       "      <td>405864986514130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.179798e+11</td>\n",
       "      <td>uchicago</td>\n",
       "      <td>487</td>\n",
       "      <td>Gunjan Kumari</td>\n",
       "      <td>...</td>\n",
       "      <td>300.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>-98.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-98.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>2111090155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SubmissionDate            starttime              endtime  \\\n",
       "0  2021-11-13 19:10:21  2021-11-13 13:12:59  2021-11-13 13:23:11   \n",
       "\n",
       "           deviceid     subscriberid simid  devicephonenum  username  \\\n",
       "0  ef443f91bed409a9  405864986514130   NaN    9.179798e+11  uchicago   \n",
       "\n",
       "   duration interviewer_name  ... i_spend_entertainment i_totalexp  \\\n",
       "0       487    Gunjan Kumari  ...                 300.0     3250.0   \n",
       "\n",
       "  i_expenditure i_savings i_loan i_loan_amt i_loan_rate i_highest i_lowest  \\\n",
       "0       11000.0     -98.0    Yes     6000.0         2.0     -98.0   3000.0   \n",
       "\n",
       "  formdef_version  \n",
       "0      2111090155  \n",
       "\n",
       "[1 rows x 65 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Yes' '-100' 'No' '-1']\n"
     ]
    }
   ],
   "source": [
    "#  unique values in the 'agree' column\n",
    "unue_iqvalues = df['agree'].unique()\n",
    "\n",
    "# Display the unique values -100 and -1 i have alredy done 0 as no and 1 as yes\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Yes' 'Did not consent' 'No' 'Refused to answer']\n"
     ]
    }
   ],
   "source": [
    "# Replace '-100' with 'Error' and '-1' with 'Unknown'\n",
    "df['agree'] = df['agree'].replace({'-100': 'Did not consent', '-1': 'Refused to answer'})\n",
    "\n",
    "# Verify the change\n",
    "print(df['agree'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SubmissionDate</th>\n",
       "      <th>starttime</th>\n",
       "      <th>endtime</th>\n",
       "      <th>deviceid</th>\n",
       "      <th>subscriberid</th>\n",
       "      <th>simid</th>\n",
       "      <th>devicephonenum</th>\n",
       "      <th>username</th>\n",
       "      <th>duration</th>\n",
       "      <th>interviewer_name</th>\n",
       "      <th>...</th>\n",
       "      <th>i_spend_entertainment</th>\n",
       "      <th>i_totalexp</th>\n",
       "      <th>i_expenditure</th>\n",
       "      <th>i_savings</th>\n",
       "      <th>i_loan</th>\n",
       "      <th>i_loan_amt</th>\n",
       "      <th>i_loan_rate</th>\n",
       "      <th>i_highest</th>\n",
       "      <th>i_lowest</th>\n",
       "      <th>formdef_version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-11-13 19:10:21</td>\n",
       "      <td>2021-11-13 13:12:59</td>\n",
       "      <td>2021-11-13 13:23:11</td>\n",
       "      <td>ef443f91bed409a9</td>\n",
       "      <td>405864986514130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.179798e+11</td>\n",
       "      <td>uchicago</td>\n",
       "      <td>487</td>\n",
       "      <td>Gunjan Kumari</td>\n",
       "      <td>...</td>\n",
       "      <td>300.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>-98.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-98.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>2111090155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-11-13 19:10:22</td>\n",
       "      <td>2021-11-13 13:24:01</td>\n",
       "      <td>2021-11-13 13:35:51</td>\n",
       "      <td>ef443f91bed409a9</td>\n",
       "      <td>405864986514130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.179798e+11</td>\n",
       "      <td>uchicago</td>\n",
       "      <td>661</td>\n",
       "      <td>Gunjan Kumari</td>\n",
       "      <td>...</td>\n",
       "      <td>250.0</td>\n",
       "      <td>3099.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>-98.0</td>\n",
       "      <td>No</td>\n",
       "      <td>58458.609756</td>\n",
       "      <td>0.07317073170731707</td>\n",
       "      <td>-98.0</td>\n",
       "      <td>-98.0</td>\n",
       "      <td>2111131313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-11-13 19:10:22</td>\n",
       "      <td>2021-11-13 13:39:04</td>\n",
       "      <td>2021-11-13 13:50:27</td>\n",
       "      <td>ef443f91bed409a9</td>\n",
       "      <td>405864986514130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.179798e+11</td>\n",
       "      <td>uchicago</td>\n",
       "      <td>659</td>\n",
       "      <td>Gunjan Kumari</td>\n",
       "      <td>...</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>-98.0</td>\n",
       "      <td>No</td>\n",
       "      <td>58458.609756</td>\n",
       "      <td>0.07317073170731707</td>\n",
       "      <td>-98.0</td>\n",
       "      <td>-98.0</td>\n",
       "      <td>2111131313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-11-13 19:10:23</td>\n",
       "      <td>2021-11-13 17:04:27</td>\n",
       "      <td>2021-11-13 17:14:15</td>\n",
       "      <td>ef443f91bed409a9</td>\n",
       "      <td>405864986514130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.179798e+11</td>\n",
       "      <td>uchicago</td>\n",
       "      <td>588</td>\n",
       "      <td>Gunjan Kumari</td>\n",
       "      <td>...</td>\n",
       "      <td>700.0</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>2111131313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-11-13 19:10:23</td>\n",
       "      <td>2021-11-13 17:15:16</td>\n",
       "      <td>2021-11-13 17:25:23</td>\n",
       "      <td>ef443f91bed409a9</td>\n",
       "      <td>405864986514130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.179798e+11</td>\n",
       "      <td>uchicago</td>\n",
       "      <td>568</td>\n",
       "      <td>Gunjan Kumari</td>\n",
       "      <td>...</td>\n",
       "      <td>500.0</td>\n",
       "      <td>2250.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>No</td>\n",
       "      <td>58458.609756</td>\n",
       "      <td>0.07317073170731707</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-98.0</td>\n",
       "      <td>2111131313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-11-13 19:10:24</td>\n",
       "      <td>2021-11-13 17:25:40</td>\n",
       "      <td>2021-11-13 17:36:30</td>\n",
       "      <td>ef443f91bed409a9</td>\n",
       "      <td>405864986514130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.179798e+11</td>\n",
       "      <td>uchicago</td>\n",
       "      <td>574</td>\n",
       "      <td>Gunjan Kumari</td>\n",
       "      <td>...</td>\n",
       "      <td>400.0</td>\n",
       "      <td>2150.0</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>-98.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-98.0</td>\n",
       "      <td>-98.0</td>\n",
       "      <td>2111131313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-11-13 19:10:24</td>\n",
       "      <td>2021-11-13 17:38:00</td>\n",
       "      <td>2021-11-13 17:48:37</td>\n",
       "      <td>ef443f91bed409a9</td>\n",
       "      <td>405864986514130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.179798e+11</td>\n",
       "      <td>uchicago</td>\n",
       "      <td>599</td>\n",
       "      <td>Gunjan Kumari</td>\n",
       "      <td>...</td>\n",
       "      <td>400.0</td>\n",
       "      <td>2700.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-98.0</td>\n",
       "      <td>-98.0</td>\n",
       "      <td>2111131313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-11-13 19:10:25</td>\n",
       "      <td>2021-11-13 17:50:18</td>\n",
       "      <td>2021-11-13 17:56:49</td>\n",
       "      <td>ef443f91bed409a9</td>\n",
       "      <td>405864986514130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.179798e+11</td>\n",
       "      <td>uchicago</td>\n",
       "      <td>392</td>\n",
       "      <td>Gunjan Kumari</td>\n",
       "      <td>...</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4800.0</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>No</td>\n",
       "      <td>58458.609756</td>\n",
       "      <td>0.07317073170731707</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>2111131313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-11-13 19:13:50</td>\n",
       "      <td>2021-11-11 15:16:04</td>\n",
       "      <td>2021-11-13 19:06:54</td>\n",
       "      <td>359475073412828</td>\n",
       "      <td>405864986514130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>contact@outlineindia.com</td>\n",
       "      <td>2085</td>\n",
       "      <td>Simaila</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>5799.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>No</td>\n",
       "      <td>58458.609756</td>\n",
       "      <td>0.07317073170731707</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2111111118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-11-13 19:13:50</td>\n",
       "      <td>2021-11-13 12:21:52</td>\n",
       "      <td>2021-11-13 19:05:57</td>\n",
       "      <td>359475073412828</td>\n",
       "      <td>405864986514130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>contact@outlineindia.com</td>\n",
       "      <td>1170</td>\n",
       "      <td>Simaila Kumari</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>7199.0</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>No</td>\n",
       "      <td>58458.609756</td>\n",
       "      <td>0.07317073170731707</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>2111111118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SubmissionDate            starttime              endtime  \\\n",
       "0  2021-11-13 19:10:21  2021-11-13 13:12:59  2021-11-13 13:23:11   \n",
       "1  2021-11-13 19:10:22  2021-11-13 13:24:01  2021-11-13 13:35:51   \n",
       "2  2021-11-13 19:10:22  2021-11-13 13:39:04  2021-11-13 13:50:27   \n",
       "3  2021-11-13 19:10:23  2021-11-13 17:04:27  2021-11-13 17:14:15   \n",
       "4  2021-11-13 19:10:23  2021-11-13 17:15:16  2021-11-13 17:25:23   \n",
       "5  2021-11-13 19:10:24  2021-11-13 17:25:40  2021-11-13 17:36:30   \n",
       "6  2021-11-13 19:10:24  2021-11-13 17:38:00  2021-11-13 17:48:37   \n",
       "7  2021-11-13 19:10:25  2021-11-13 17:50:18  2021-11-13 17:56:49   \n",
       "8  2021-11-13 19:13:50  2021-11-11 15:16:04  2021-11-13 19:06:54   \n",
       "9  2021-11-13 19:13:50  2021-11-13 12:21:52  2021-11-13 19:05:57   \n",
       "\n",
       "           deviceid     subscriberid simid  devicephonenum  \\\n",
       "0  ef443f91bed409a9  405864986514130   NaN    9.179798e+11   \n",
       "1  ef443f91bed409a9  405864986514130   NaN    9.179798e+11   \n",
       "2  ef443f91bed409a9  405864986514130   NaN    9.179798e+11   \n",
       "3  ef443f91bed409a9  405864986514130   NaN    9.179798e+11   \n",
       "4  ef443f91bed409a9  405864986514130   NaN    9.179798e+11   \n",
       "5  ef443f91bed409a9  405864986514130   NaN    9.179798e+11   \n",
       "6  ef443f91bed409a9  405864986514130   NaN    9.179798e+11   \n",
       "7  ef443f91bed409a9  405864986514130   NaN    9.179798e+11   \n",
       "8   359475073412828  405864986514130   NaN             NaN   \n",
       "9   359475073412828  405864986514130   NaN             NaN   \n",
       "\n",
       "                   username  duration interviewer_name  ...  \\\n",
       "0                  uchicago       487    Gunjan Kumari  ...   \n",
       "1                  uchicago       661    Gunjan Kumari  ...   \n",
       "2                  uchicago       659    Gunjan Kumari  ...   \n",
       "3                  uchicago       588    Gunjan Kumari  ...   \n",
       "4                  uchicago       568    Gunjan Kumari  ...   \n",
       "5                  uchicago       574    Gunjan Kumari  ...   \n",
       "6                  uchicago       599    Gunjan Kumari  ...   \n",
       "7                  uchicago       392    Gunjan Kumari  ...   \n",
       "8  contact@outlineindia.com      2085          Simaila  ...   \n",
       "9  contact@outlineindia.com      1170   Simaila Kumari  ...   \n",
       "\n",
       "  i_spend_entertainment i_totalexp i_expenditure i_savings i_loan  \\\n",
       "0                 300.0     3250.0       11000.0     -98.0    Yes   \n",
       "1                 250.0     3099.0        6000.0     -98.0     No   \n",
       "2                1000.0     7000.0       20000.0     -98.0     No   \n",
       "3                 700.0     3200.0       16000.0    4000.0    Yes   \n",
       "4                 500.0     2250.0       10000.0    3000.0     No   \n",
       "5                 400.0     2150.0       12000.0     -98.0    Yes   \n",
       "6                 400.0     2700.0        8000.0    1000.0    Yes   \n",
       "7                 800.0     4800.0       16000.0    5000.0     No   \n",
       "8                    No     5799.0        8000.0   15000.0     No   \n",
       "9                    No     7199.0       12000.0     -99.0     No   \n",
       "\n",
       "     i_loan_amt          i_loan_rate i_highest i_lowest formdef_version  \n",
       "0   6000.000000                  2.0     -98.0   3000.0      2111090155  \n",
       "1  58458.609756  0.07317073170731707     -98.0    -98.0      2111131313  \n",
       "2  58458.609756  0.07317073170731707     -98.0    -98.0      2111131313  \n",
       "3  50000.000000                  5.0   25000.0   5000.0      2111131313  \n",
       "4  58458.609756  0.07317073170731707     -99.0    -98.0      2111131313  \n",
       "5  10000.000000                  2.0     -98.0    -98.0      2111131313  \n",
       "6  20000.000000                  3.0     -98.0    -98.0      2111131313  \n",
       "7  58458.609756  0.07317073170731707     -99.0    -99.0      2111131313  \n",
       "8  58458.609756  0.07317073170731707     -99.0   1000.0      2111111118  \n",
       "9  58458.609756  0.07317073170731707   10000.0   5000.0      2111111118  \n",
       "\n",
       "[10 rows x 65 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Yes' 'No' nan '-999.0']\n"
     ]
    }
   ],
   "source": [
    "# View unique values in the 'hh_BPL_bin' column\n",
    "unique_values = df['hh_BPL_bin'].unique()\n",
    "print(unique_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         Yes\n",
      "1         Yes\n",
      "2          No\n",
      "3         Yes\n",
      "4          No\n",
      "5          No\n",
      "6         Yes\n",
      "7         Yes\n",
      "8          No\n",
      "9         Yes\n",
      "10        Yes\n",
      "11        NaN\n",
      "12         No\n",
      "13         No\n",
      "14        Yes\n",
      "15        Yes\n",
      "16         No\n",
      "17        Yes\n",
      "18        Yes\n",
      "19        Yes\n",
      "20        Yes\n",
      "21        Yes\n",
      "22        Yes\n",
      "23         No\n",
      "24        Yes\n",
      "25         No\n",
      "26        Yes\n",
      "27        Yes\n",
      "28        NaN\n",
      "29        Yes\n",
      "30         No\n",
      "31         No\n",
      "32         No\n",
      "33         No\n",
      "34         No\n",
      "35         No\n",
      "36         No\n",
      "37         No\n",
      "38        Yes\n",
      "39        Yes\n",
      "40        Yes\n",
      "41        Yes\n",
      "42        Yes\n",
      "43        Yes\n",
      "44        Yes\n",
      "45        Yes\n",
      "46         No\n",
      "47         No\n",
      "48         No\n",
      "49        Yes\n",
      "50        Yes\n",
      "51         No\n",
      "52         No\n",
      "53         No\n",
      "54         No\n",
      "55         No\n",
      "56        Yes\n",
      "57        Yes\n",
      "58        Yes\n",
      "59        Yes\n",
      "60         No\n",
      "61         No\n",
      "62        Yes\n",
      "63         No\n",
      "64        Yes\n",
      "65        Yes\n",
      "66        NaN\n",
      "67         No\n",
      "68        Yes\n",
      "69        Yes\n",
      "70        Yes\n",
      "71        Yes\n",
      "72         No\n",
      "73        Yes\n",
      "74        NaN\n",
      "75         No\n",
      "76        Yes\n",
      "77        Yes\n",
      "78         No\n",
      "79         No\n",
      "80        Yes\n",
      "81        Yes\n",
      "82         No\n",
      "83        Yes\n",
      "84         No\n",
      "85        Yes\n",
      "86     -999.0\n",
      "87         No\n",
      "88        Yes\n",
      "89        Yes\n",
      "90         No\n",
      "91        Yes\n",
      "92        Yes\n",
      "93        NaN\n",
      "94        NaN\n",
      "95        Yes\n",
      "96        NaN\n",
      "97        NaN\n",
      "98        Yes\n",
      "99        Yes\n",
      "100       NaN\n",
      "101       Yes\n",
      "102       Yes\n",
      "103       Yes\n",
      "104       Yes\n",
      "105        No\n",
      "106        No\n",
      "107       NaN\n",
      "108        No\n",
      "109        No\n",
      "110       Yes\n",
      "111       NaN\n",
      "112       Yes\n",
      "113       Yes\n",
      "114       Yes\n",
      "115        No\n",
      "116       Yes\n",
      "117       Yes\n",
      "118       Yes\n",
      "119        No\n",
      "120       Yes\n",
      "121       Yes\n",
      "122       Yes\n",
      "123       Yes\n",
      "124       Yes\n",
      "125        No\n",
      "126        No\n",
      "127        No\n",
      "128       Yes\n",
      "129       Yes\n",
      "130        No\n",
      "131        No\n",
      "132       Yes\n",
      "133        No\n",
      "134        No\n",
      "135       Yes\n",
      "136       Yes\n",
      "137       Yes\n",
      "138       Yes\n",
      "139       Yes\n",
      "140       Yes\n",
      "141       Yes\n",
      "142       Yes\n",
      "143       Yes\n",
      "144       Yes\n",
      "145       Yes\n",
      "146       Yes\n",
      "Name: hh_BPL_bin, dtype: object\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "print(df['hh_BPL_bin'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    }
   ],
   "source": [
    "print(df['hh_BPL_bin'].dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace '-999' and '-999.0' (as strings) with 'Don't know' in the 'hh_BPL_bin' column\n",
    "df['hh_BPL_bin'] = df['hh_BPL_bin'].replace({'-999': 'Don\\'t know', '-999.0': 'Don\\'t know'})\n",
    "\n",
    "# Verify the change\n",
    "print(df['hh_BPL_bin'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique values for specific columns\n",
    "columns_to_check = ['el_source', 'el_source_1', 'el_source_2', 'el_source_3', 'el_source_4', 'el_source_5', 'el_source__999', 'el_source__1', 'el_source__100']\n",
    "\n",
    "for column in columns_to_check:\n",
    "    unique_values = df[column].unique()\n",
    "    print(f\"Unique values in {column}: {unique_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Yes' '1 5' 'nan' '1 3']\n"
     ]
    }
   ],
   "source": [
    "df['el_source'] = df['el_source'].astype(str).str.strip()\n",
    "\n",
    "# Replace 1 with 'Yes'\n",
    "df['el_source'] = df['el_source'].replace({'1': 'Yes'})\n",
    "\n",
    "print(df['el_source'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_check = ['el_bill_bin', 'el_bill_date', 'el_bill_amt']\n",
    "\n",
    "for column in columns_to_check:\n",
    "    unique_values = df[column].unique()\n",
    "    print(f\"Unique values in {column}: {unique_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Strip any leading/trailing whitespaces before replacing\n",
    "df['el_bill_bin'] = df['el_bill_bin'].str.strip()\n",
    "\n",
    "# Replace '-1.0' with 'Refused to answer'\n",
    "df['el_bill_bin'] = df['el_bill_bin'].replace({'-1.0': 'Refused to answer'})\n",
    "\n",
    "# Verify the change\n",
    "print(df['el_bill_bin'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Replace '-100' with 'Did not consent' and '-999.0' with 'Don't know'\n",
    "df['el_bill_date'] = df['el_bill_date'].replace({-100: 'Did not consent', -999.0: 'Don\\'t know'})\n",
    "print(df['el_bill_date'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_check = ['el_pay_freq', 'el_pay_freq', 'el_pay_freq']\n",
    "\n",
    "for column in columns_to_check:\n",
    "    unique_values = df[column].unique()\n",
    "    print(f\"Unique values in {column}: {unique_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "replacement_dict = {\n",
    "    '3.0': 'Every 3 months',\n",
    "    'Yes': 'Monthly',\n",
    "    '2.0': 'Every two months',\n",
    "    '4.0': 'Less than once in 3 months',\n",
    "    '5.0': 'Other',\n",
    "    '-999.0': 'Don\\'t know'\n",
    "}\n",
    "\n",
    "df['el_pay_freq'] = df['el_pay_freq'].replace(replacement_dict)\n",
    "\n",
    "print(df['el_pay_freq'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['el_pay_freq'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'el_unpaid_reason_2', 'el_unpaid_reason_3', 'el_unpaid_reason_4',\n",
    "    'el_unpaid_reason_5', 'el_unpaid_reason_6', 'el_unpaid_reason_7',\n",
    "    'el_unpaid_reason_8', 'el_unpaid_reason__999', 'el_unpaid_reason__1', 'el_unpaid_reason__100'\n",
    "]\n",
    "\n",
    "# Check the unique values in each of the specified columns\n",
    "for col in columns:\n",
    "    print(f\"Unique values in {col}:\")\n",
    "    print(df[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['el_right']\n",
    "\n",
    "# Check the unique values in each of the specified columns\n",
    "for col in columns:\n",
    "    print(f\"Unique values in {col}:\")\n",
    "    print(df[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['el_right'] = df['el_right'].replace({'-999.0':'Don\\'t know', '-1.0':'Refused to answer', 'Very unlikely': 'Yes'})\n",
    "print(df['el_right'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['el_notice']\n",
    "\n",
    "# Check the unique values in each of the specified columns\n",
    "for col in columns:\n",
    "    print(f\"Unique values in {col}:\")\n",
    "    print(df[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['el_notice'] = df['el_notice'].astype(str)\n",
    "\n",
    "# these are specific values with corresponding labels\n",
    "df['el_notice'] = df['el_notice'].replace({\n",
    "    '-999.0': \"Don't know\",\n",
    "    '-1.0': 'Refused to answer',\n",
    "    '5.0': 'Very Likely',\n",
    "    '4.0': 'Somewhat likely',\n",
    "    '3.0': 'Neither unlikely or likely',\n",
    "    '2.0': 'Somewhat unlikely',\n",
    "    '-100.0': 'Does not consent',\n",
    "    'Yes': 'Very unlikely',\n",
    "})\n",
    "\n",
    "\n",
    "print(\"Unique values in el_notice after replacement:\")\n",
    "print(df['el_notice'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['el_unpaid_nbr']\n",
    "\n",
    "# Check the unique values in each of the specified columns\n",
    "for col in columns:\n",
    "    print(f\"Unique values in {col}:\")\n",
    "    print(df[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace values in 'el_unpaid_nbr' with labels\n",
    "df['el_unpaid_nbr'] = df['el_unpaid_nbr'].replace({\n",
    "    '4.0': 'Almost everybody pays on time and in full',                   \n",
    "    '3.0': 'More than 50 percent pay on time and in full',               \n",
    "    '2.0': 'Less than 50 percent pay on time and in full',   \n",
    "    '-999.0': \"Don\\'t know\",                 \n",
    "    '-1.0': 'Refused to answer',           \n",
    "    '-100.0': 'Does not consent',           \n",
    "    'Yes': 'Almost nobody pays on time in full',                                    \n",
    "})\n",
    "\n",
    "print(\"Unique values in el_unpaid_nbr after replacement:\")\n",
    "print(df['el_unpaid_nbr'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['el_disconnect'] = df['el_disconnect'].replace({\n",
    "    \n",
    "    '-999.0': \"Don\\'t know\",                 \n",
    "    '-1.0': 'Refused to answer',                                               \n",
    "})\n",
    "\n",
    "print(df['el_disconnect'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['i_source']\n",
    "\n",
    "# Check the unique values in each of the specified columns\n",
    "for col in columns:\n",
    "    print(f\"Unique values in {col}:\")\n",
    "    print(df[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the replacements for i_source\n",
    "i_source_labels = {\n",
    "    'Yes': 'Agriculture and related activities',\n",
    "    '2.0': 'Pension and Income',\n",
    "    '3.0': 'Small business',\n",
    "    '4.0': 'Professional',\n",
    "    '5.0': 'Small industry/mill/factory',\n",
    "    '6.0': 'Transportation',\n",
    "    '7.0': 'Construction',\n",
    "    '8.0': 'Income from remittances',\n",
    "    '9.0': 'Rent/dividend',\n",
    "    '10.0': 'Forest based livelihood',\n",
    "    '11.0': 'Other',\n",
    "    '-999.0': 'Don\\'t know',\n",
    "    '-1.0': 'Refused to answer',\n",
    "    '-100.0': \"Did not consent\",\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "df['i_source'] = df['i_source'].astype(str)\n",
    "\n",
    "df['i_source'] = df['i_source'].replace(i_source_labels)\n",
    "\n",
    "\n",
    "print(\"Unique values in i_source after replacement:\")\n",
    "print(df['i_source'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['i_loan']\n",
    "\n",
    "# Check the unique values in each of the specified columns\n",
    "for col in columns:\n",
    "    print(f\"Unique values in {col}:\")\n",
    "    print(df[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_loan_labels = {\n",
    "    '-999.0': \"Don't know\",\n",
    "    '-1.0': 'Refused to answer',\n",
    "    '-100.0': \"Did not consent\"\n",
    "}\n",
    "\n",
    "df['i_loan'] = df['i_loan'].astype(str)\n",
    "df['i_loan'] = df['i_loan'].replace(i_loan_labels)\n",
    "\n",
    "\n",
    "print(\"Unique values in i_loan after replacement:\")\n",
    "print(df['i_loan'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to a new CSV file\n",
    "df.to_csv('C:/Users/2023/Downloads/dataset/labeled_data.csv', index=False)\n",
    "#here i have save my cleaned data to a new csv file named labeled_data.csv \n",
    "print(\"CSV file saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "df = pd.read_csv('C:/Users/2023/Downloads/dataset/labeled_data.csv')    #loaded the data from the csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for cleaning further anlysis i will drop some of the irrelavent columns\n",
    "\n",
    "df = df.drop(columns=['SubmissionDate', 'starttime', 'endtime', 'deviceid', 'subscriberid', 'simid', 'devicephonenum', 'username'], errors='ignore')\n",
    "\n",
    "#no use of this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Likely related to internal mapping\n",
    "\n",
    "df= df.drop(columns=['list_id', 'list_id_1'] ,errors= 'ignore')   #droped irrelavent columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['el_disconnect'] = df['el_disconnect'].replace({'Yes': 1})\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#  the average loan amount by unpaid reason\n",
    "loan_by_unpaid_reason = df.groupby('el_unpaid_reason')['i_loan_amt'].mean().sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=loan_by_unpaid_reason.index, y=loan_by_unpaid_reason.values, palette='Set2')\n",
    "plt.title('Average Loan Amount by Unpaid Reason', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Reason for Unpaid Bill', fontsize=14)\n",
    "plt.ylabel('Average Loan Amount (in USD)', fontsize=14)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['el_unpaid_reason'] = df['el_unpaid_reason'].replace({\n",
    "    1: \"Can't afford to pay\",\n",
    "    2: \"No punishment for late payments\",\n",
    "    3: \"Service quality is poor\",\n",
    "    4: \"Electricity is a right; shouldn't have to pay\",\n",
    "    5: \"Going to the payment location takes a long time\",\n",
    "    6: \"My bills are often incorrect\",\n",
    "    7: \"I always pay in full\",\n",
    "    8: \"Other\",\n",
    "    -999: \"Don't know\",\n",
    "    -1: \"Refused to answer\",\n",
    "    -100: \"Did not consent/didn't reach this question\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average loan amount by unpaid reason\n",
    "loan_by_unpaid_reason = (\n",
    "    df.groupby('el_unpaid_reason')['i_loan_amt']\n",
    "    .mean()\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(\n",
    "    x=loan_by_unpaid_reason.index,\n",
    "    y=loan_by_unpaid_reason.values,\n",
    "    hue=loan_by_unpaid_reason.index,\n",
    "    palette='Set2',\n",
    "    dodge=False \n",
    ")\n",
    "\n",
    "plt.title('Average Loan Amount by Unpaid Reason', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Reason for Unpaid Bill', fontsize=14)\n",
    "plt.ylabel('Average Loan Amount (in USD)', fontsize=14)\n",
    "plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "plt.legend([], [], frameon=False) \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Income Source vs Loan Amount\n",
    "income_vs_loan = df.groupby('i_source')['i_loan_amt'].mean()\n",
    "print(\"\\nAverage Loan Amount by Income Source:\")\n",
    "print(income_vs_loan)\n",
    "\n",
    "# Bar plot for Income Source vs Loan Amount (fix for the FutureWarning)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=income_vs_loan.index, y=income_vs_loan.values, hue=income_vs_loan.index, palette='Set2', legend=False)\n",
    "plt.title('Loan Amount by Income Source', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Income Source', fontsize=14)\n",
    "plt.ylabel('Average Loan Amount', fontsize=14)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['hh_size'] = pd.to_numeric(df['hh_size'], errors='coerce')\n",
    "df['el_hours'] = pd.to_numeric(df['el_hours'], errors='coerce')\n",
    "\n",
    "# Calculate the correlation between household size and electricity hours\n",
    "correlation = df[['hh_size', 'el_hours']].corr()\n",
    "print(\"\\nCorrelation between household size and electricity hours:\")\n",
    "print(correlation)\n",
    "\n",
    "grouped_by_size = df.groupby('hh_size')['el_hours'].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.lineplot(x='hh_size', y='el_hours', data=grouped_by_size, marker='o', color='blue')\n",
    "plt.title('Average Electricity Hours by Household Size', fontsize=14)\n",
    "plt.xlabel('Household Size', fontsize=12)\n",
    "plt.ylabel('Average Electricity Hours', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('C:/Users/2023/Downloads/dataset/labeled_dataa.csv', index=False)\n",
    "\n",
    "print(\"CSV file saved successfully!\")     #saved file as an backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_bill = df['el_bill_amt'].mean()\n",
    "min_bill = df['el_bill_amt'].min()\n",
    "max_bill = df['el_bill_amt'].max()\n",
    "median_bill = df['el_bill_amt'].median()\n",
    "std_dev = df['el_bill_amt'].std()\n",
    "\n",
    "print(f\"Mean Bill Amount: {mean_bill}\")\n",
    "print(f\"Minimum Bill Amount: {min_bill}\")\n",
    "print(f\"Maximum Bill Amount: {max_bill}\")\n",
    "print(f\"Median Bill Amount: {median_bill}\")\n",
    "print(f\"Standard Deviation: {std_dev}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram for bill amounts\n",
    "plt.hist(df['el_bill_amt'], bins=10, color='blue', edgecolor='black')\n",
    "plt.title('Distribution of Bill Amounts')\n",
    "plt.xlabel('Bill Amount (in Rupees)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hh_size\n",
      "10.0    3100.250000\n",
      "11.0    2200.000000\n",
      "12.0    1500.000000\n",
      "13.0    1500.000000\n",
      "15.0    1450.500000\n",
      "2.0     1400.000000\n",
      "20.0     300.000000\n",
      "3.0     1185.125000\n",
      "4.0     1200.447368\n",
      "5.0      825.500000\n",
      "6.0     1327.000000\n",
      "7.0     3002.363636\n",
      "8.0     1141.100000\n",
      "9.0     1675.000000\n",
      "Yes             NaN\n",
      "Name: el_bill_amt, dtype: float64\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "agg function failed [how->mean,dtype->object]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\2023\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1942\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[1;34m(self, how, values, ndim, alt)\u001b[0m\n\u001b[0;32m   1941\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1942\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_grouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1943\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\2023\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:864\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[1;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[0;32m    862\u001b[0m     preserve_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 864\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_aggregate_series_pure_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    866\u001b[0m npvalues \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmaybe_convert_objects(result, try_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\2023\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:885\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[1;34m(self, obj, func)\u001b[0m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(splitter):\n\u001b[1;32m--> 885\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    886\u001b[0m     res \u001b[38;5;241m=\u001b[39m extract_result(res)\n",
      "File \u001b[1;32mc:\\Users\\2023\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:2454\u001b[0m, in \u001b[0;36mGroupBy.mean.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   2451\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2452\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_agg_general(\n\u001b[0;32m   2453\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m-> 2454\u001b[0m         alt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   2455\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[0;32m   2456\u001b[0m     )\n\u001b[0;32m   2457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\2023\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:6549\u001b[0m, in \u001b[0;36mSeries.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m   6541\u001b[0m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m   6542\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[0;32m   6543\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6547\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   6548\u001b[0m ):\n\u001b[1;32m-> 6549\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNDFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\2023\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:12420\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  12413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[0;32m  12414\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  12415\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  12418\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  12419\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m> 12420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  12421\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m  12422\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\2023\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:12377\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  12375\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m> 12377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  12378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[0;32m  12379\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\2023\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:6457\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   6453\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   6454\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6455\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith non-numeric dtypes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6456\u001b[0m     )\n\u001b[1;32m-> 6457\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\2023\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\nanops.py:147\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 147\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\2023\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\nanops.py:404\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[1;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[0;32m    402\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[1;32m--> 404\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n",
      "File \u001b[1;32mc:\\Users\\2023\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\nanops.py:720\u001b[0m, in \u001b[0;36mnanmean\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    719\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39msum(axis, dtype\u001b[38;5;241m=\u001b[39mdtype_sum)\n\u001b[1;32m--> 720\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m \u001b[43m_ensure_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthe_sum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\2023\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\nanops.py:1701\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1699\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1700\u001b[0m     \u001b[38;5;66;03m# GH#44008, GH#36703 avoid casting e.g. strings to numeric\u001b[39;00m\n\u001b[1;32m-> 1701\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not convert string \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to numeric\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1702\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not convert string '500.0' to numeric",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(mean_bill_by_hh_size)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Group by BPL status and calculate mean savings\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m mean_savings_by_bpl \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhh_BPL_bin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mi_savings\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(mean_savings_by_bpl)\n",
      "File \u001b[1;32mc:\\Users\\2023\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:2452\u001b[0m, in \u001b[0;36mGroupBy.mean\u001b[1;34m(self, numeric_only, engine, engine_kwargs)\u001b[0m\n\u001b[0;32m   2445\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numba_agg_general(\n\u001b[0;32m   2446\u001b[0m         grouped_mean,\n\u001b[0;32m   2447\u001b[0m         executor\u001b[38;5;241m.\u001b[39mfloat_dtype_mapping,\n\u001b[0;32m   2448\u001b[0m         engine_kwargs,\n\u001b[0;32m   2449\u001b[0m         min_periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   2450\u001b[0m     )\n\u001b[0;32m   2451\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2452\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cython_agg_general\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2453\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2454\u001b[0m \u001b[43m        \u001b[49m\u001b[43malt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2456\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\2023\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1998\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general\u001b[1;34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[0;32m   1995\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(how, values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n\u001b[0;32m   1996\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m-> 1998\u001b[0m new_mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouped_reduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1999\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_agged_manager(new_mgr)\n\u001b[0;32m   2000\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midxmin\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midxmax\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\2023\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\base.py:367\u001b[0m, in \u001b[0;36mSingleDataManager.grouped_reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrouped_reduce\u001b[39m(\u001b[38;5;28mself\u001b[39m, func):\n\u001b[0;32m    366\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray\n\u001b[1;32m--> 367\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    368\u001b[0m     index \u001b[38;5;241m=\u001b[39m default_index(\u001b[38;5;28mlen\u001b[39m(res))\n\u001b[0;32m    370\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_array(res, index)\n",
      "File \u001b[1;32mc:\\Users\\2023\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1995\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m   1992\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m   1994\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m alt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1995\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_agg_py_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1996\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\2023\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1946\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[1;34m(self, how, values, ndim, alt)\u001b[0m\n\u001b[0;32m   1944\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magg function failed [how->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,dtype->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mser\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1945\u001b[0m     \u001b[38;5;66;03m# preserve the kind of exception that raised\u001b[39;00m\n\u001b[1;32m-> 1946\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(err)(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ser\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m   1949\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m res_values\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: agg function failed [how->mean,dtype->object]"
     ]
    }
   ],
   "source": [
    "# Group by household size and calculate mean bill amount\n",
    "mean_bill_by_hh_size = df.groupby('hh_size')['el_bill_amt'].mean()\n",
    "print(mean_bill_by_hh_size)\n",
    "\n",
    "# Group by BPL status and calculate mean savings\n",
    "mean_savings_by_bpl = df.groupby('hh_BPL_bin')['i_savings'].mean()\n",
    "print(mean_savings_by_bpl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average bill amount by payment frequency\n",
    "avg_bill_by_pay_freq = df.groupby('el_pay_freq')['el_bill_amt'].mean()\n",
    "print(avg_bill_by_pay_freq)\n",
    "\n",
    "# Group by interviewer and calculate average bill amount\n",
    "avg_bill_by_interviewer = df.groupby('interviewer_name')['el_bill_amt'].mean()\n",
    "print(avg_bill_by_interviewer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram for bill amount distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['el_bill_amt'], kde=True)\n",
    "plt.title('Distribution of Bill Amounts')\n",
    "plt.xlabel('Bill Amount')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# chart for household BPL statusie\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[0;32m      3\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhh_BPL_bin\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;241m.\u001b[39mplot\u001b[38;5;241m.\u001b[39mpie(autopct\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%1.1f\u001b[39;00m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;124m'\u001b[39m, colors\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#ff9999\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#66b3ff\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#99ff99\u001b[39m\u001b[38;5;124m'\u001b[39m], startangle\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m90\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDistribution of Household BPL Status\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# chart for household BPL statusie\n",
    "plt.figure(figsize=(8, 8))\n",
    "df['hh_BPL_bin'].value_counts().plot.pie(autopct='%1.1f%%', colors=['#ff9999','#66b3ff','#99ff99'], startangle=90)\n",
    "plt.title('Distribution of Household BPL Status')\n",
    "plt.ylabel('')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "Report= ProfileReport(df, title =\"Data Profiling Report\", html={\"style\": {\"full_width\": True}})\n",
    "#for report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Report.to_file(output_file='analysis.html')     #it saves the report in html form"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
